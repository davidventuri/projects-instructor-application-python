{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to your DataCamp project audition! This notebook must be filled out and vetted before a contract can be signed and you can start creating your project.\n",
    "\n",
    "The first step is forking the repository in which this notebook lives. After that, there are two parts to be completed in this notebook:\n",
    "\n",
    "- **Project information**:  The title of the project, a project description, etc.\n",
    "\n",
    "- **Project introduction**: The three first text and code cells that will form the introduction of your project.\n",
    "\n",
    "When complete, please email the link to your forked repo to projects@datacamp.com with the email subject line _DataCamp project audition_. If you have any questions, please reach out to projects@datacamp.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project title**: What programming languages do Data Scientists use?\n",
    "\n",
    "**Name:** Upendra Kumar Devisetty\n",
    "\n",
    "**Email address associated with your DataCamp account:** upendrakumar.devisetty@googlemail.com\n",
    "\n",
    "**Project description**:\n",
    "\n",
    "What programming languages do world's Data scientists and Machine learning specialists use to code? What about the programming languages they want to use next year? Knowing the answers to these questions helps aspiring Data scientists to plan their career. One excellent source of this information is [Stack Overflow Annual Developer Survey](https://insights.stackoverflow.com/survey). In addition to programming language questions, the survey capture all aspects of the developer's experience ranging from career satisfaction and job search for education, salaries, hobbies, and sound preference when coding etc., \n",
    "\n",
    "In this project, you'll use the public data release of [Stack Overflow’s 2018 Developer Survey](https://insights.stackoverflow.com/survey/2018) which consists of 98,855 responses from around the world making it the world’s largest and most comprehensive developer survey. As part of this project, you'll examine the preference of programming languages among Data scientists and Machine learning specialists across the world this year and their desired programming languages to use in the next year.\n",
    "\n",
    "This project lets you practice the skills acquired from [Big Data Fundamentals via PySpark](https://www.datacamp.com/courses/big-data-fundamentals-via-pyspark), [Pandas Foundations](https://www.datacamp.com/courses/pandas-foundations) and [Introduction to Data Visualization with Python](https://www.datacamp.com/courses/introduction-to-data-visualization-with-python), including DataFrame operations (reading, grouping, sorting, filtering) using PySpark, DataFrame manipulations using Pandas and finally visualizing with Matplotlib and Seaborn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project introduction\n",
    "\n",
    "***Note: nothing needs to be filled out in this cell. It is simply setting up the template cells below.***\n",
    "\n",
    "The final output of a DataCamp project looks like a blog post: pairs of text and code cells that tell a story about data. The text is written from the perspective of the data analyst and *not* from the perspective of an instructor on DataCamp. So, for this blog post intro, all you need to do is pretend like you're writing a blog post -- forget the part about instructors and students.\n",
    "\n",
    "Below you'll see the structure of a DataCamp project: a series of \"tasks\" where each task consists of a title, a **single** text cell, and a **single** code cell. There are 8-12 tasks in a project and each task can have up to 10 lines of code. What you need to do:\n",
    "1. Read through the template structure.\n",
    "2. As best you can, divide your project as it is currently visualized in your mind into tasks.\n",
    "3. Fill out the template structure for the first three tasks of your project.\n",
    "\n",
    "As you are completing each task, you may wish to consult the project notebook format in our [documentation](https://instructor-support.datacamp.com/projects/datacamp-projects-jupyter-notebook). Only the `@context` and `@solution` cells are relevant to this audition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and subset the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data science is booming and shows no signs of slowing down in the near future. Because of that, it’s becoming increasingly important to learn what programming languages the professionals (Data scientists and machine learning specialists) who make up this field currently use, and what they desired to use in the next year. These are the kinds of questions that [Stack Overflow](https://stackoverflow.com/) which is the most popular question and answer site for professional and enthusiast programmers wanted to find out from their developers in their [2018 annual Developer survey](https://insights.stackoverflow.com/survey/2018). The 2018 survey consists of over 100,000 respondents from around the world, making it the world’s largest and most comprehensive developer survey. Knowing what languages the developers currently use and desire to use in the next year will help the aspiring Data scientists make informed decisions about their data science career. \n",
    "\n",
    "![survey](img/survey2.png)\n",
    "\n",
    "We will load the 2018 survey dataset with one observation for each Data Science and Machine learning but we'll work with a subset of survey dataset columns i.e type of developer, the languages they currently work with and the languages they desired to work next year.\n",
    "\n",
    "You already have a SparkSession `spark` available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load dataset into PySpark DataFrame\n",
    "df = spark.read.csv(\"datasets/survey_results_public_ds_ml.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Inspect the DataFrame \n",
    "df.show(10)\n",
    "\n",
    "# Subset the DataFrame \n",
    "df_sub = df.select('DevType', 'LanguageWorkedWith', 'LanguageDesireNextYear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Let's filter Data scientists now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After subsetting the interested columns, we will filter Data scientists and machine learning specialists from the `DevType` column. This allows us to keep only those rows which we are interested in going forward. Inspecting the resulting dataframe shows you that there are NA's in both \"LanguageWorkedWith\" and \"LanguageDesireNextYear\" columns. Let's remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter the dataset for \"Data scientist or machine learning specialist\"\n",
    "df2 = df_sub.filter(df_sub.DevType == \"Data scientist or machine learning specialist\")\n",
    "\n",
    "# Remove NA's from \"LanguageWorkedWith\" column\n",
    "df3 = df2.filter(df_sub.LanguageWorkedWith != \"NA\")\n",
    "\n",
    "# Remove NA's from \"LanguageDesireNextYear\" column\n",
    "df4 = df2.filter(df_sub.LanguageDesireNextYear != \"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pandarize your PySpark DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization works best with Pandas Dataframes compared to PySpark DataFrame. So let's first convert df3 and df4 PySpark DataFrames into Pandas DataFrames. This data has one observation for DevType, LanguageWorkedWith and LanguageDesireNextYear columns. For example in the first observation, \"LanguageWorkedWith\" has languages - \"Java;JavaScript;Scala;SQL;HTML;CSS\" and \"LanguageDesireNextYear\" has languages \"Haskell;Scala;SQL;Bash/Shell\"\n",
    "\n",
    "Next is splitting the languages based on \";\" separator in both \"LanguageWorkedWith\" and \"LanguageDesireNextYear\" columns and generating counts for the different languages for the respective columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Covert to Pandas\n",
    "df3_pandas = df3.toPandas()\n",
    "df4_pandas = df4.toPandas()\n",
    "\n",
    "# Print the header of the two Pandas DataFrames\n",
    "df3_pandas.head()\n",
    "df4_pandas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Stop here! Only the three first tasks. :)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
